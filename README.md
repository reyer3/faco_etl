# FACO ETL ğŸš€

**Production-Ready Python ETL for GestiÃ³n de Cobranza Analytics**

Transforms BigQuery raw data into Looker Studio ready aggregated tables with:
- âœ… **Real Business Dimensions** aggregation (CARTERA, CANAL, OPERADOR, etc.)
- âœ… **Working Days Calculations** with Peru holidays
- âœ… **First-Time Tracking** per client and dimension
- âœ… **Period-over-Period Comparisons** using same business day logic
- âœ… **Actions vs Unique Clients** differentiated metrics
- âœ… **Temporal Validation** ensuring gestiÃ³n within perÃ­odo vigencia

---

## ğŸ­ **For Presentations & Live Demos**

### **Quick Start (2 minutes)**
```bash
# 1. Clone and setup
git clone https://github.com/reyer3/faco_etl.git
cd faco_etl

# 2. Install dependencies  
pip install -r requirements.txt

# 3. Setup credentials (choose one):
# Option A: Using gcloud (recommended)
gcloud auth application-default login

# Option B: Service account key
mkdir credentials
# Copy your service-account.json to credentials/key.json

# 4. Validate everything is ready
python validate_etl.py

# 5. Run ETL in presentation mode
python presentation_express.py
```

### **Live Demo Commands**
```bash
# Quick health check
python validate_etl.py

# Express ETL execution with real-time metrics
python presentation_express.py 2025-06 abierto

# Debug mode with detailed logging
python main.py --mes 2025-06 --estado abierto --debug

# Dry-run mode (safe for demos)
python main.py --mes 2025-06 --estado abierto --dry-run
```

---

## ğŸ“Š **Business Value Delivered**

### **Input: Raw BigQuery Tables**
- `batch_*_asignacion`: Portfolio assignments (165K+ accounts)  
- `voicebot_*`: Automated gestiÃ³n (1.2M+ interactions)
- `mibotair_*`: Human gestiÃ³n (2M+ interactions)
- `batch_*_tran_deuda`: Debt amounts by account
- `batch_*_pagos`: Payment transactions

### **Output: Looker Studio Ready Tables**
- **`dash_cobranza_agregada`**: Main dashboard table with all KPIs
- **`dash_cobranza_comparativas`**: Period-over-period analysis
- **`dash_primera_vez_tracking`**: First-time contact tracking
- **`dash_cobranza_base_cartera`**: Portfolio coverage analysis

### **Key Business Metrics Generated**
- **Contactability Rate**: % accounts reached per channel
- **Effectiveness Rate**: % successful contacts per total attempts  
- **First-Time Success**: New clients contacted successfully
- **Channel Performance**: BOT vs HUMAN efficiency comparison
- **Working Days Analysis**: Same business day period comparisons
- **Portfolio Recovery**: Payment rates by portfolio type

---

## ğŸ—ï¸ **Technical Architecture**

### **ETL Pipeline Flow**
```
ğŸ“Š BigQuery Raw Data
    â†“ Extract (with temporal validation)
ğŸ”„ Python Transformation Engine  
    â†“ Business dimensions + KPIs
ğŸ“Š BigQuery Optimized Tables
    â†“ Partitioned + Clustered
ğŸ“ˆ Looker Studio Dashboards
```

### **Key Innovations**
- **Temporal Validation**: Gestiones only within valid perÃ­odo vigencia
- **Business Days Engine**: Peru holiday calendar with configurable rules
- **First-Time Tracking**: Client-dimension combination tracking
- **Intelligent Aggregation**: Actions vs unique clients differentiation
- **Auto-Optimization**: BigQuery tables optimized for Looker Studio

---

## ğŸ”§ **Production Setup**

### **Docker Deployment**
```bash
# Production run
docker-compose up etl

# Development mode with hot-reload
docker-compose up dev

# Interactive debugging shell
docker-compose run --rm shell
```

### **Environment Configuration**
```bash
# Copy and customize
cp .env.example .env

# Key variables:
GOOGLE_CLOUD_PROJECT=mibot-222814
BIGQUERY_DATASET=BI_USA
MES_VIGENCIA=2025-06
ESTADO_VIGENCIA=abierto
COUNTRY_CODE=PE
OUTPUT_TABLE_PREFIX=dash_cobranza
```

---

## ğŸ“ˆ **Performance & Scale**

### **Processing Capabilities**
- **~165K accounts/minute** processing rate
- **3M+ interactions** aggregated efficiently  
- **Sub-2-minute** end-to-end execution
- **Real-time** BigQuery integration

### **Looker Studio Optimization**
- **Partitioned tables** by date for fast queries
- **Clustered fields** (CARTERA, CANAL, OPERADOR) for instant filtering
- **Pre-aggregated KPIs** eliminate complex JOINs
- **Wide table format** enables drag-and-drop analytics

---

## ğŸ§ª **Quality & Validation**

### **Data Quality Checks**
- **Temporal consistency** validation
- **Business rules** enforcement  
- **Duplicate detection** across key dimensions
- **Null value** monitoring in critical fields
- **Cross-table** relationship validation

### **Testing & Monitoring**
```bash
# Run test suite
pytest tests/

# Data quality validation
python validate_etl.py

# Performance monitoring
python main.py --debug --dry-run
```

---

## ğŸ¯ **Business Impact Delivered**

### **Before FACO ETL**
- âŒ **Manual** SQL aggregations taking hours
- âŒ **Inconsistent** metrics across teams  
- âŒ **No period comparisons** with business day logic
- âŒ **Complex JOINs** slowing Looker Studio
- âŒ **No first-time tracking** capabilities

### **After FACO ETL**  
- âœ… **Automated** daily processing in <2 minutes
- âœ… **Standardized** KPIs across organization
- âœ… **Intelligent** period-over-period comparisons  
- âœ… **Optimized** tables for instant Looker Studio response
- âœ… **Advanced** client lifecycle tracking

---

## ğŸ† **Key Differentiators**

1. **Real Business Logic**: Incorporates dÃ­as hÃ¡biles, temporal validation, first-time tracking
2. **Production Ready**: Docker, logging, error handling, data quality validation
3. **Looker Optimized**: Purpose-built for fast dashboard performance  
4. **Scalable Architecture**: Modular design supports growth and new requirements
5. **KISS & DRY**: Simple to operate, maintainable codebase

---

## ğŸ› ï¸ **Development**

### **Local Development**
```bash
# Setup development environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements-dev.txt

# Code quality
black src/
flake8 src/
mypy src/

# Run tests
pytest tests/ -v
```

### **Module Structure**
```
src/
â”œâ”€â”€ core/           # Configuration, orchestration, logging
â”œâ”€â”€ etl/            # Business logic modules
â”‚   â”œâ”€â”€ extractor.py      # BigQuery data extraction
â”‚   â”œâ”€â”€ transformer.py    # Business rules & aggregation  
â”‚   â”œâ”€â”€ loader.py         # Optimized BigQuery loading
â”‚   â”œâ”€â”€ business_days.py  # Working days calculation
â”‚   â””â”€â”€ queries.py        # SQL query templates
â””â”€â”€ tests/          # Comprehensive test suite
```

---

## ğŸ“‹ **Requirements**

- **Python 3.9+** with pandas, google-cloud-bigquery
- **Google Cloud credentials** with BigQuery access
- **BigQuery dataset** with source tables
- **Docker** (optional but recommended)

---

## ğŸ“ **Support & Documentation**

- **Getting Started**: See `GETTING_STARTED.md`
- **Troubleshooting**: Run `python validate_etl.py` for diagnostics  
- **Logs**: Check `logs/etl.log` for detailed execution info
- **Performance**: Use `--debug` flag for timing analysis

---

## ğŸ“„ **License**

MIT License - See `LICENSE` file for details

---

**Built for production cobranza analytics. Optimized for Looker Studio. Ready for scale.**